{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T10:46:47.619724Z",
     "iopub.status.busy": "2024-07-07T10:46:47.619027Z",
     "iopub.status.idle": "2024-07-07T10:51:45.222799Z",
     "shell.execute_reply": "2024-07-07T10:51:45.220866Z",
     "shell.execute_reply.started": "2024-07-07T10:46:47.619666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install wandb\n",
    "# import pandas as pd\n",
    "# from datasets import Dataset\n",
    "# from transformers import AutoTokenizer\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# import torch\n",
    "# from torch.utils.data import DataLoader\n",
    "# from transformers import AutoModelForSequenceClassification, AdamW, get_scheduler\n",
    "# from tqdm.auto import tqdm\n",
    "# from transformers import TrainingArguments, Trainer\n",
    "# import wandb\n",
    "# import numpy as np\n",
    "\n",
    "# # Initialize WandB with your API key\n",
    "# wandb.login(key=\"92009a9c5dd6b5b7a30a3f921b700b85af6651cb\")\n",
    "\n",
    "# # Load your dataset from CSV\n",
    "# data = pd.read_csv('/kaggle/input/dianostic-final-dataset/final_dataset.csv')\n",
    "\n",
    "# # Print data types of each column in the dataset\n",
    "# print(\"Data types of each column in the dataset:\")\n",
    "# print(data.dtypes)\n",
    "# print()\n",
    "\n",
    "# # Encode labels as integers\n",
    "# label_encoder = LabelEncoder()\n",
    "# data['subreddit'] = label_encoder.fit_transform(data['subreddit'])\n",
    "\n",
    "# # Load BERT tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-multilingual-cased\")\n",
    "\n",
    "# # Tokenize function\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples['post'], padding='max_length', truncation=True)\n",
    "\n",
    "# # Convert Pandas DataFrame to Dataset\n",
    "# dataset = Dataset.from_pandas(data)\n",
    "\n",
    "# # Tokenize dataset\n",
    "# tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# # Add labels to the tokenized dataset\n",
    "# tokenized_datasets = tokenized_datasets.add_column(\"labels\", data['subreddit'].tolist())\n",
    "\n",
    "# # Split into train and test datasets\n",
    "# train_test_split = tokenized_datasets.train_test_split(test_size=0.2)\n",
    "# train_dataset = train_test_split['train']\n",
    "# eval_dataset = train_test_split['test']\n",
    "\n",
    "# # Define DataLoader\n",
    "# train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=8)\n",
    "# eval_dataloader = DataLoader(eval_dataset, batch_size=8)\n",
    "\n",
    "# # Load model for sequence classification\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-multilingual-cased\", num_labels=len(label_encoder.classes_))\n",
    "\n",
    "# # Define optimizer\n",
    "# optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# # Define learning rate scheduler\n",
    "# num_epochs = 3\n",
    "# num_training_steps = num_epochs * len(train_dataloader)\n",
    "# lr_scheduler = get_scheduler(\n",
    "#     name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    "# )\n",
    "\n",
    "# # Install and import the evaluate module\n",
    "# !pip install evaluate\n",
    "# import evaluate\n",
    "\n",
    "# # Define metric\n",
    "# metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# # Compute metrics function\n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# # Define training arguments\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"/kaggle/working/\",\n",
    "#     evaluation_strategy=\"steps\",\n",
    "#     eval_steps=1000,\n",
    "#     logging_steps=1000,\n",
    "#     num_train_epochs=num_epochs,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     warmup_steps=500,\n",
    "#     weight_decay=0.01,\n",
    "#     logging_dir='/kaggle/working/logs',\n",
    "# )\n",
    "\n",
    "# # Initialize Trainer\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=eval_dataset,\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n",
    "\n",
    "# # Train the model with WandB integration\n",
    "# trainer.train()\n",
    "\n",
    "# # Finish WandB run\n",
    "# wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T06:47:31.804588Z",
     "iopub.status.busy": "2024-07-07T06:47:31.804188Z",
     "iopub.status.idle": "2024-07-07T06:47:33.235767Z",
     "shell.execute_reply": "2024-07-07T06:47:33.234734Z",
     "shell.execute_reply.started": "2024-07-07T06:47:31.804558Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Save the model and tokenizer\n",
    "# model.save_pretrained(\"/kaggle/working/saved_model\")\n",
    "# tokenizer.save_pretrained(\"/kaggle/working/saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T08:50:15.816763Z",
     "iopub.status.busy": "2024-07-07T08:50:15.815982Z",
     "iopub.status.idle": "2024-07-07T08:50:16.698832Z",
     "shell.execute_reply": "2024-07-07T08:50:16.697945Z",
     "shell.execute_reply.started": "2024-07-07T08:50:15.816723Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# # Load the model and tokenizer\n",
    "# model_path = \"/kaggle/working/saved_model\"\n",
    "# print(f\"Loading model from: {model_path}\")\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "# print(\"Model loaded successfully.\")\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "# print(\"Tokenizer loaded successfully.\")\n",
    "\n",
    "# # Example usage:\n",
    "# input_text = \"Losing it. Lately I haven’t felt like a real person. And I don’t know if that’s the right way to describe it. I’m always in my head, always thinking and overthinking but never ever about anything that actually matters. Nothing excites me anymore, I can’t focus on anything for too long. All I do is sleep, I am exhausted 99% of the time. When I’m not at work I’ll sometimes sleep for literally my entire off day. I can’t keep up with chores. I have a hard time showering/brushing my teeth which makes me feel so disgusting. I hate my job. I’m getting very bored in my relationship even though I love him to death. I feel very alone because he doesn’t get it and we go through the same motions and conversations every day. Basically I don’t have any plans or directions for my life, everything scares me, and I have no idea what to do. Nothing seems to help and no one seems to understand. I just downloaded this app and decided to post here because I have no one to talk to and I am so scared.\"\n",
    "# print(f\"Input text: {input_text}\")\n",
    "\n",
    "# inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "# print(\"Tokenized input:\", inputs)\n",
    "\n",
    "# outputs = model(**inputs)\n",
    "# print(\"Model outputs:\", outputs)\n",
    "\n",
    "# import torch\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming 'outputs' is the SequenceClassifierOutput object as shown\n",
    "# logits = outputs.logits\n",
    "# predictions = torch.argmax(logits, dim=-1)\n",
    "# predicted_class_index = predictions.item()\n",
    "\n",
    "# # Decode the predicted class using label_encoder\n",
    "# predicted_class = label_encoder.classes_[predicted_class_index]\n",
    "\n",
    "# print(\"Predicted Class:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T07:01:31.802720Z",
     "iopub.status.busy": "2024-07-07T07:01:31.801790Z",
     "iopub.status.idle": "2024-07-07T07:02:10.084377Z",
     "shell.execute_reply": "2024-07-07T07:02:10.083134Z",
     "shell.execute_reply.started": "2024-07-07T07:01:31.802677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !zip -r file.zip /kaggle/working/saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T07:02:28.091592Z",
     "iopub.status.busy": "2024-07-07T07:02:28.090902Z",
     "iopub.status.idle": "2024-07-07T07:02:28.102185Z",
     "shell.execute_reply": "2024-07-07T07:02:28.101231Z",
     "shell.execute_reply.started": "2024-07-07T07:02:28.091554Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from IPython.display import FileLink\n",
    "# FileLink(r'file.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T08:18:58.796555Z",
     "iopub.status.busy": "2024-07-07T08:18:58.795752Z",
     "iopub.status.idle": "2024-07-07T08:19:01.814746Z",
     "shell.execute_reply": "2024-07-07T08:19:01.813660Z",
     "shell.execute_reply.started": "2024-07-07T08:18:58.796519Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T12:50:17.271192Z",
     "iopub.status.busy": "2024-07-13T12:50:17.270583Z",
     "iopub.status.idle": "2024-07-13T15:12:59.418409Z",
     "shell.execute_reply": "2024-07-13T15:12:59.417561Z",
     "shell.execute_reply.started": "2024-07-13T12:50:17.271160Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from transformers import TFBertForSequenceClassification, BertTokenizerFast\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('/kaggle/input/dianostic-final-dataset/final_dataset.csv')\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('google-bert/bert-base-multilingual-cased')\n",
    "\n",
    "label_map = {\"addiction\": 0, \"anxiety\": 1, \"depression\": 2, \"PTSD\": 3}\n",
    "\n",
    "# Load the model\n",
    "model = TFBertForSequenceClassification.from_pretrained('google-bert/bert-base-multilingual-cased', num_labels=len(label_map))\n",
    "\n",
    "# Define a simple function to tokenize the texts\n",
    "def tokenize_function(texts):\n",
    "    return tokenizer(texts, padding='max_length', truncation=True, max_length=512, return_tensors='tf')\n",
    "\n",
    "# Prepare the data\n",
    "def prepare_dataset(df, label_map):\n",
    "    texts = df['post'].tolist()\n",
    "    labels = df['subreddit'].map(label_map).tolist()\n",
    "    \n",
    "    encodings = tokenize_function(texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        dict(encodings),\n",
    "        labels\n",
    "    ))\n",
    "    return dataset\n",
    "\n",
    "train_dataset = prepare_dataset(train_df, label_map)\n",
    "eval_dataset = prepare_dataset(eval_df, label_map)\n",
    "\n",
    "# Shuffle and batch the datasets\n",
    "train_dataset = train_dataset.shuffle(len(train_df)).batch(8)\n",
    "eval_dataset = eval_dataset.batch(8)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 3\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=eval_dataset,\n",
    "    epochs=num_epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T15:18:34.656710Z",
     "iopub.status.busy": "2024-07-13T15:18:34.656034Z",
     "iopub.status.idle": "2024-07-13T15:19:49.934294Z",
     "shell.execute_reply": "2024-07-13T15:19:49.933449Z",
     "shell.execute_reply.started": "2024-07-13T15:18:34.656678Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save('/kaggle/working/diagnosis_model_bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T16:28:21.607261Z",
     "iopub.status.busy": "2024-07-13T16:28:21.606414Z",
     "iopub.status.idle": "2024-07-13T16:28:21.698646Z",
     "shell.execute_reply": "2024-07-13T16:28:21.697672Z",
     "shell.execute_reply.started": "2024-07-13T16:28:21.607209Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained('/kaggle/working/diagnosis_model_bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T16:10:40.404808Z",
     "iopub.status.busy": "2024-07-13T16:10:40.404434Z",
     "iopub.status.idle": "2024-07-13T16:10:51.704402Z",
     "shell.execute_reply": "2024-07-13T16:10:51.703502Z",
     "shell.execute_reply.started": "2024-07-13T16:10:40.404780Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('/kaggle/working/diagnosis_model_bert-base-multilingual-cased')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T16:29:07.919838Z",
     "iopub.status.busy": "2024-07-13T16:29:07.919489Z",
     "iopub.status.idle": "2024-07-13T16:29:22.078637Z",
     "shell.execute_reply": "2024-07-13T16:29:22.077649Z",
     "shell.execute_reply.started": "2024-07-13T16:29:07.919809Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizerFast\n",
    "import numpy as np\n",
    "\n",
    "# Load the fine-tuned model\n",
    "new_model = tf.keras.models.load_model('/kaggle/working/diagnosis_model_bert-base-multilingual-cased')\n",
    "\n",
    "# Prepare the tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('/kaggle/working/diagnosis_model_bert-base-multilingual-cased')\n",
    "\n",
    "# Define a function to tokenize new input data\n",
    "def tokenize_function(texts):\n",
    "    return tokenizer(texts, padding='max_length', truncation=True, max_length=512, return_tensors='tf')\n",
    "\n",
    "# Example input\n",
    "new_texts = [\"i am feeling sad and lonely\", \"i was sexually assualted when i was 8 years old, i can not cope up with that\"]\n",
    "\n",
    "# Tokenize the input texts\n",
    "new_encodings = tokenize_function(new_texts)\n",
    "\n",
    "# Make predictions\n",
    "predictions = new_model.predict(dict(new_encodings))\n",
    "\n",
    "# Extract logits from predictions dictionary\n",
    "logits = predictions['logits']\n",
    "\n",
    "# Apply softmax to get probabilities\n",
    "probs = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "# Determine the predicted labels\n",
    "predicted_labels = np.argmax(probs, axis=1)\n",
    "\n",
    "# Assuming you have a label map\n",
    "label_map = {\n",
    "    'Addiction': 0,\n",
    "    'Anxiety': 1,\n",
    "    'Depression': 2,\n",
    "    'PTSD': 3\n",
    "}\n",
    "\n",
    "# Create a reverse label map\n",
    "reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "# Get the class names of the predicted labels\n",
    "predicted_class_names = [reverse_label_map[label] for label in predicted_labels]\n",
    "\n",
    "# Print the predicted labels and their class names\n",
    "print(predicted_labels)\n",
    "print(predicted_class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T16:36:37.442868Z",
     "iopub.status.busy": "2024-07-13T16:36:37.442088Z",
     "iopub.status.idle": "2024-07-13T16:37:59.862863Z",
     "shell.execute_reply": "2024-07-13T16:37:59.861691Z",
     "shell.execute_reply.started": "2024-07-13T16:36:37.442833Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!zip -r file.zip /kaggle/working/diagnosis_model_bert-base-multilingual-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T16:38:51.856064Z",
     "iopub.status.busy": "2024-07-13T16:38:51.855283Z",
     "iopub.status.idle": "2024-07-13T16:38:51.862913Z",
     "shell.execute_reply": "2024-07-13T16:38:51.862022Z",
     "shell.execute_reply.started": "2024-07-13T16:38:51.856027Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'file.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T19:29:54.124137Z",
     "iopub.status.busy": "2024-07-13T19:29:54.123725Z",
     "iopub.status.idle": "2024-07-13T19:29:54.820162Z",
     "shell.execute_reply": "2024-07-13T19:29:54.819254Z",
     "shell.execute_reply.started": "2024-07-13T19:29:54.124104Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"YOUR_HUGGINGFACE_TOKEN\", add_to_git_credential=True, new_session=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T16:59:09.641581Z",
     "iopub.status.busy": "2024-07-13T16:59:09.640798Z",
     "iopub.status.idle": "2024-07-13T16:59:27.354450Z",
     "shell.execute_reply": "2024-07-13T16:59:27.353676Z",
     "shell.execute_reply.started": "2024-07-13T16:59:09.641543Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.push_to_hub(\"SiddharthShukla48/MindAid_Diagnosis_bert-base-multilingual-cased\")\n",
    "\n",
    "tokenizer.push_to_hub(\"SiddharthShukla48/MindAid_Diagnosis_bert-base-multilingual-cased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T17:01:29.266922Z",
     "iopub.status.busy": "2024-07-13T17:01:29.266162Z",
     "iopub.status.idle": "2024-07-13T17:01:44.425986Z",
     "shell.execute_reply": "2024-07-13T17:01:44.425361Z",
     "shell.execute_reply.started": "2024-07-13T17:01:29.266889Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"SiddharthShukla48/MindAid_Diagnosis_bert-base-multilingual-cased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"SiddharthShukla48/MindAid_Diagnosis_bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T19:25:41.161525Z",
     "iopub.status.busy": "2024-07-13T19:25:41.161225Z",
     "iopub.status.idle": "2024-07-13T19:25:45.540200Z",
     "shell.execute_reply": "2024-07-13T19:25:45.538673Z",
     "shell.execute_reply.started": "2024-07-13T19:25:41.161499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip list"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5345648,
     "sourceId": 8883681,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
